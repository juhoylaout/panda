{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dda58b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "daa9bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1e22714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dev_data(data_file):\n",
    "    df = pd.read_csv(data_file)\n",
    "    texts = df['text'].tolist()\n",
    "    labels = df['label'].tolist() \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0c1226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"dev_2024.csv\"\n",
    "texts, labels = load_dev_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "783c4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ddce5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pooled_output = outputs.pooler_output\n",
    "            x = self.dropout(pooled_output)\n",
    "            logits = self.fc(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3dafa9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "59a0d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9a98326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "    return \"positive\" if preds.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "068d27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 2\n",
    "max_length = 128\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf3519a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1c099805",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc559528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1310dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "540cc52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     accuracy, report \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataloader, device)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [105]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(outputs, labels)\n\u001b[0;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 11\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m func \u001b[38;5;241m=\u001b[39m method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m instance_ref()\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m method\n\u001b[0;32m     70\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     72\u001b[0m     instance \u001b[38;5;241m=\u001b[39m instance_ref()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m                 s[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(s[i])\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Common doc strings among optimizers\u001b[39;00m\n\u001b[0;32m    136\u001b[0m _foreach_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mforeach (bool, optional): whether foreach implementation of optimizer\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124m            is used. If unspecified by the user (so foreach is None), we will try to use\u001b[39m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124m            foreach over the for-loop implementation on CUDA, since it is usually\u001b[39m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124m            significantly more performant. Note that the foreach implementation uses\u001b[39m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;124m            ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\u001b[39m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124m            being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124m            parameters through the optimizer at a time or switch this flag to False (default: None)\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    144\u001b[0m _fused_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mfused (bool, optional): whether the fused implementation (CUDA only) is used.\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124m            Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\u001b[39m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124m            are supported. (default: None)\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124m              we want to give it sufficient bake-in time, so we default to foreach and NOT\u001b[39m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124m              fused when the user has not specified either flag.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    161\u001b[0m _capturable_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mcapturable (bool, optional): whether this instance is safe to\u001b[39m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124m            capture in a CUDA graph. Passing True can impair ungraphed performance,\u001b[39m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124m            so if you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt intend to graph capture this instance, leave it False\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124m            (default: False)\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mno_grad\u001b[39;00m(_NoParamDecoratorContextManager):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Context-manager that disables gradient calculation.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    Disabling gradient calculation is useful for inference, when you are sure\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    that you will not call :meth:`Tensor.backward()`. It will reduce memory\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    consumption for computations that would otherwise have `requires_grad=True`.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;124;03m    In this mode, the result of every computation will have\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    `requires_grad=False`, even when the inputs have `requires_grad=True`.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    There is an exception! All factory functions, or functions that create\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    a new Tensor and take a requires_grad kwarg, will NOT be affected by\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    this mode.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    This context manager is thread local; it will not affect computation\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    in other threads.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Also functions as a decorator.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m        No-grad is one of several mechanisms that can enable or\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m        disable gradients locally see :ref:`locally-disable-grad-doc` for\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m        more information on how they compare.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m        If you want to disable forward AD for a computation, you can unpack\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m        your dual tensors.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    Example::\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +SKIP\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m        >>> x = torch.tensor([1.], requires_grad=True)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        >>> with torch.no_grad():\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m        ...     y = x * 2\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        >>> y.requires_grad\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        False\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m        >>> @torch.no_grad()\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m        ... def doubler(x):\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m        ...     return x * 2\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m        >>> z = doubler(x)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m        >>> z.requires_grad\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m        False\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m        >>> @torch.no_grad\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m        ... def tripler(x):\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m        ...     return x * 3\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m        >>> z = tripler(x)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m        >>> z.requires_grad\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m        False\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m        >>> # factory function exception\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m        >>> with torch.no_grad():\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m        ...     a = torch.nn.Parameter(torch.rand(10))\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m        >>> a.requires_grad\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m        True\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_jit_internal\u001b[38;5;241m.\u001b[39mis_scripting():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py:162\u001b[0m, in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cuda_graph_capture_health_check()\n\u001b[0;32m    161\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m    164\u001b[0m         loss \u001b[38;5;241m=\u001b[39m closure()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py:219\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    187\u001b[0m             adamw(\n\u001b[0;32m    188\u001b[0m                 params_with_grad,\n\u001b[0;32m    189\u001b[0m                 grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m                 has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    208\u001b[0m             )\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m    213\u001b[0m AdamW\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mImplements AdamW algorithm.\u001b[39m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;124m    .. math::\u001b[39m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124m       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;132;01m{aligned}\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                                 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m      : \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(lr)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2\u001b[39m\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(betas)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(params)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: f(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta) \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(objective)},\u001b[39m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m (epsilon)}                                                    \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{13mm}\u001b[39;00m\u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(weight decay)},  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;132;01m{amsgrad}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;132;01m{maximize}\u001b[39;00m\u001b[38;5;124m                                                             \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{initialize}\u001b[39;00m\u001b[38;5;124m : m_0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow 0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m (first moment)}, v_0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow 0\u001b[39m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m ( second moment)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_0}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow 0              \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                                 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{for}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: t=1 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{to}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mldots \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{do}\u001b[39;00m\u001b[38;5;124m                         \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    227\u001b[0m \n\u001b[0;32m    228\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{if}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;132;01m{maximize}\u001b[39;00m\u001b[38;5;124m:                                       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124mg_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   -\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnabla_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta} f_t (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1})          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{else}\u001b[39;00m\u001b[38;5;124m                                                           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124mg_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnabla_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta} f_t (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1})           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1} - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1}         \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124mm_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1 m_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1} + (1 - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1) g_t          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124mv_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2 v_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1} + (1-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2) g^2_t          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{m_t}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   m_t/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(1-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1^t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   v_t/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(1-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2^t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{if}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: amsgrad                                                  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmathrm\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m)                                                                   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{m_t}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m} + \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                                 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{else}\u001b[39;00m\u001b[38;5;124m                                                           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{m_t}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m} + \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                                       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbf\u001b[39m\u001b[38;5;132;01m{return}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t                                                     \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124m       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;132;01m{aligned}\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;124m    For further details regarding the algorithm we refer to `Decoupled Weight Decay Regularization`_.\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124m    Args:\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124m        params (iterable): iterable of parameters to optimize or dicts defining\u001b[39m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124m            parameter groups\u001b[39m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124m        lr (float, Tensor, optional): learning rate (default: 1e-3). A tensor LR\u001b[39m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124m            is not yet supported for all our implementations. Please use a float\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124m            LR if you are not also specifying fused=True or capturable=True.\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124m        betas (Tuple[float, float], optional): coefficients used for computing\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124m            running averages of gradient and its square (default: (0.9, 0.999))\u001b[39m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124m        eps (float, optional): term added to the denominator to improve\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124m            numerical stability (default: 1e-8)\u001b[39m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124m        weight_decay (float, optional): weight decay coefficient (default: 1e-2)\u001b[39m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124m        amsgrad (bool, optional): whether to use the AMSGrad variant of this\u001b[39m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124m            algorithm from the paper `On the Convergence of Adam and Beyond`_\u001b[39m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124m            (default: False)\u001b[39m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_maximize_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_foreach_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_capturable_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_differentiable_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_fused_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124m    .. _Decoupled Weight Decay Regularization:\u001b[39m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124m        https://arxiv.org/abs/1711.05101\u001b[39m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124m    .. _On the Convergence of Adam and Beyond:\u001b[39m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124m        https://openreview.net/forum?id=ryQu7f-RZ\u001b[39m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madamw\u001b[39m(\n\u001b[0;32m    280\u001b[0m     params: List[Tensor],\n\u001b[0;32m    281\u001b[0m     grads: List[Tensor],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m     maximize: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m    303\u001b[0m ):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Functional API that performs AdamW algorithm computation.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.optim.AdamW` for details.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py:270\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    187\u001b[0m             adamw(\n\u001b[0;32m    188\u001b[0m                 params_with_grad,\n\u001b[0;32m    189\u001b[0m                 grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m                 has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    208\u001b[0m             )\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m    213\u001b[0m AdamW\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mImplements AdamW algorithm.\u001b[39m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;124m    .. math::\u001b[39m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124m       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;132;01m{aligned}\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                                 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m      : \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(lr)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2\u001b[39m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(betas)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(params)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: f(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta) \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(objective)},\u001b[39m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m (epsilon)}                                                    \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{13mm}\u001b[39;00m\u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(weight decay)},  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;132;01m{amsgrad}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;132;01m{maximize}\u001b[39;00m\u001b[38;5;124m                                                             \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{initialize}\u001b[39;00m\u001b[38;5;124m : m_0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow 0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m (first moment)}, v_0 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow 0\u001b[39m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m ( second moment)}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_0}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow 0              \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                                 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{for}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: t=1 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{to}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mldots \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{do}\u001b[39;00m\u001b[38;5;124m                         \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    227\u001b[0m \n\u001b[0;32m    228\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{if}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;132;01m{maximize}\u001b[39;00m\u001b[38;5;124m:                                       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124mg_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   -\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnabla_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta} f_t (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1})          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{else}\u001b[39;00m\u001b[38;5;124m                                                           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124mg_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnabla_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta} f_t (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1})           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1} - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1}         \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124mm_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1 m_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1} + (1 - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1) g_t          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124mv_t           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2 v_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mt-1} + (1-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2) g^2_t          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{m_t}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   m_t/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(1-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_1^t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow   v_t/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(1-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbeta_2^t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{if}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m: amsgrad                                                  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmathrm\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m)                                                                   \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{m_t}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m^\u001b[39m\u001b[38;5;132;01m{max}\u001b[39;00m\u001b[38;5;124m} + \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                                 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{5mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtextbf\u001b[39m\u001b[38;5;132;01m{else}\u001b[39;00m\u001b[38;5;124m                                                           \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;132;01m{10mm}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleftarrow \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgamma \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{m_t}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwidehat\u001b[39m\u001b[38;5;132;01m{v_t}\u001b[39;00m\u001b[38;5;124m} + \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbig)                                       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbf\u001b[39m\u001b[38;5;132;01m{return}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtheta_t                                                     \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124m            &\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;132;01m{110mm}\u001b[39;00m\u001b[38;5;132;01m{0.4pt}\u001b[39;00m\u001b[38;5;124m                                                          \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[-1.ex]\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124m       \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;132;01m{aligned}\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;124m    For further details regarding the algorithm we refer to `Decoupled Weight Decay Regularization`_.\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124m    Args:\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124m        params (iterable): iterable of parameters to optimize or dicts defining\u001b[39m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124m            parameter groups\u001b[39m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124m        lr (float, Tensor, optional): learning rate (default: 1e-3). A tensor LR\u001b[39m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124m            is not yet supported for all our implementations. Please use a float\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124m            LR if you are not also specifying fused=True or capturable=True.\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124m        betas (Tuple[float, float], optional): coefficients used for computing\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124m            running averages of gradient and its square (default: (0.9, 0.999))\u001b[39m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124m        eps (float, optional): term added to the denominator to improve\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124m            numerical stability (default: 1e-8)\u001b[39m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124m        weight_decay (float, optional): weight decay coefficient (default: 1e-2)\u001b[39m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124m        amsgrad (bool, optional): whether to use the AMSGrad variant of this\u001b[39m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124m            algorithm from the paper `On the Convergence of Adam and Beyond`_\u001b[39m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124m            (default: False)\u001b[39m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_maximize_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_foreach_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_capturable_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_differentiable_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_fused_doc\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124m    .. _Decoupled Weight Decay Regularization:\u001b[39m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124m        https://arxiv.org/abs/1711.05101\u001b[39m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124m    .. _On the Convergence of Adam and Beyond:\u001b[39m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124m        https://openreview.net/forum?id=ryQu7f-RZ\u001b[39m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madamw\u001b[39m(\n\u001b[0;32m    280\u001b[0m     params: List[Tensor],\n\u001b[0;32m    281\u001b[0m     grads: List[Tensor],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m     maximize: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m    303\u001b[0m ):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Functional API that performs AdamW algorithm computation.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.optim.AdamW` for details.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bert_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e665974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"The movie was great and I really enjoyed the performances of the actors.\"\n",
    "toxicity = predict_toxicity(test_text, model, tokenizer, device)\n",
    "print(\"The movie was great and I really enjoyed the performances of the actors.\")\n",
    "print(f\"Predicted sentiment: {toxicity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2107cd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.13.1+cpu\n",
      "Is CUDA enabled? False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b6b5ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 23 14:15:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro P2200                 WDDM  | 00000000:65:00.0  On |                  N/A |\n",
      "| 46%   34C    P8               7W /  75W |   1048MiB /  5120MiB |     29%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1108    C+G   ...\\Programs\\signal-desktop\\Signal.exe    N/A      |\n",
      "|    0   N/A  N/A      2468    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2728    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      2792    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      3312    C+G   ...r\\AppData\\Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
      "|    0   N/A  N/A      4100    C+G   ...ppData\\Roaming\\Zoom\\bin\\CptHost.exe    N/A      |\n",
      "|    0   N/A  N/A      4588    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A      4644    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6616    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6872    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      6952    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7340    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      9712    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10252    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     10580    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     12128    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a1ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
